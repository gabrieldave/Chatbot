"""
üîç VERIFICACI√ìN DE L√çMITES TIER 3
==================================

Verifica los l√≠mites reales de OpenAI para Tier 3
y calcula el batch_size √≥ptimo
"""

import os
import sys
import requests
import json
from dotenv import load_dotenv

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

load_dotenv()

def get_env(key):
    value = os.getenv(key, "")
    if not value:
        for env_key in os.environ.keys():
            if env_key.strip().lstrip('\ufeff') == key:
                value = os.environ[env_key]
                break
    return value.strip('"').strip("'").strip()

OPENAI_API_KEY = get_env("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    print("‚ùå Error: OPENAI_API_KEY no est√° configurada")
    sys.exit(1)

headers = {
    "Authorization": f"Bearer {OPENAI_API_KEY}",
    "Content-Type": "application/json"
}

print("=" * 80)
print("üîç VERIFICACI√ìN DE L√çMITES TIER 3")
print("=" * 80)
print()

# Hacer llamada real y ver headers
print("üì° HACIENDO LLAMADA A OPENAI PARA VERIFICAR L√çMITES...")
print("-" * 80)

try:
    response = requests.post(
        "https://api.openai.com/v1/embeddings",
        headers=headers,
        json={
            "model": "text-embedding-3-small",
            "input": "test"
        },
        timeout=10
    )
    
    print(f"   Status code: {response.status_code}")
    
    # Extraer headers de rate limit
    rate_limit_info = {}
    for key, value in response.headers.items():
        if 'ratelimit' in key.lower():
            rate_limit_info[key] = value
    
    if rate_limit_info:
        print("\n‚úÖ HEADERS DE RATE LIMIT ENCONTRADOS:")
        for key, value in sorted(rate_limit_info.items()):
            print(f"   ‚Ä¢ {key}: {value}")
    
    # Analizar l√≠mites
    rpm_limit = None
    tpm_limit = None
    
    for key, value in rate_limit_info.items():
        if 'limit-requests' in key.lower():
            rpm_limit = int(value)
        elif 'limit-tokens' in key.lower():
            tpm_limit = int(value)
    
    print("\n" + "=" * 80)
    print("üìä AN√ÅLISIS DE L√çMITES")
    print("=" * 80)
    print()
    
    if rpm_limit:
        print(f"‚úÖ RPM (Requests Per Minute): {rpm_limit:,}")
    else:
        print("‚ö†Ô∏è  RPM: No detectado en headers")
        rpm_limit = 5000  # Asumir Tier 3
    
    if tpm_limit:
        print(f"‚úÖ TPM (Tokens Per Minute): {tpm_limit:,}")
        # Verificar si es Tier 3 (5M TPM)
        if tpm_limit >= 5000000:
            print("   üéØ ¬°Confirmado Tier 3! (5M+ TPM)")
        elif tpm_limit >= 1000000:
            print("   üìä Tier 2 detectado (1M+ TPM)")
        else:
            print("   üìä Tier 1 o inferior")
    else:
        print("‚ö†Ô∏è  TPM: No detectado en headers")
        tpm_limit = 5000000  # Asumir Tier 3
    
    print()
    print("=" * 80)
    print("üí° C√ÅLCULO DE BATCH_SIZE √ìPTIMO")
    print("=" * 80)
    print()
    
    # C√°lculos para Tier 3
    print("üìê PAR√ÅMETROS:")
    print(f"   ‚Ä¢ RPM l√≠mite: {rpm_limit:,}")
    print(f"   ‚Ä¢ TPM l√≠mite: {tpm_limit:,}")
    print(f"   ‚Ä¢ TPD l√≠mite: 100,000,000 (Tier 3)")
    print()
    
    # Asumir promedio de tokens por archivo
    # Un libro promedio puede tener 50,000-200,000 tokens
    # Para chunks peque√±os (512 tokens cada uno), un archivo puede generar ~100-400 chunks
    # Cada chunk = 1 request a embeddings
    
    avg_tokens_per_file = 50000  # Conservador
    avg_chunks_per_file = 100    # ~100 requests por archivo promedio
    
    print("üìä ESTIMACIONES POR ARCHIVO:")
    print(f"   ‚Ä¢ Tokens promedio: ~{avg_tokens_per_file:,}")
    print(f"   ‚Ä¢ Chunks promedio: ~{avg_chunks_per_file}")
    print(f"   ‚Ä¢ Requests promedio: ~{avg_chunks_per_file}")
    print()
    
    # Calcular batch_size √≥ptimo
    # Usar 80% del l√≠mite para seguridad
    rpm_target = int(rpm_limit * 0.8)
    tpm_target = int(tpm_limit * 0.8)
    
    print(f"üéØ OBJETIVO (80% de capacidad):")
    print(f"   ‚Ä¢ RPM objetivo: {rpm_target:,}")
    print(f"   ‚Ä¢ TPM objetivo: {tpm_target:,}")
    print()
    
    # Batch size basado en RPM
    batch_size_rpm = rpm_target // avg_chunks_per_file
    # Batch size basado en TPM
    batch_size_tpm = tpm_target // avg_tokens_per_file
    
    # Tomar el menor para respetar ambos l√≠mites
    batch_size_optimal = min(batch_size_rpm, batch_size_tpm)
    
    # Ajustar al rango recomendado (32-64)
    if batch_size_optimal < 32:
        batch_size_optimal = 32
    elif batch_size_optimal > 64:
        batch_size_optimal = 64
    
    print(f"üì¶ BATCH_SIZE √ìPTIMO:")
    print(f"   ‚Ä¢ Basado en RPM: {batch_size_rpm}")
    print(f"   ‚Ä¢ Basado en TPM: {batch_size_tpm}")
    print(f"   ‚Ä¢ √ìptimo final: {batch_size_optimal} (rango recomendado: 32-64)")
    print()
    
    # Calcular capacidad con batch actual (38)
    batch_current = 38
    requests_current = batch_current * avg_chunks_per_file
    tokens_current = batch_current * avg_tokens_per_file
    
    print(f"üìä AN√ÅLISIS CON BATCH ACTUAL ({batch_current}):")
    print(f"   ‚Ä¢ Requests por batch: ~{requests_current:,}")
    print(f"   ‚Ä¢ Tokens por batch: ~{tokens_current:,}")
    print(f"   ‚Ä¢ % de RPM l√≠mite: {(requests_current/rpm_limit)*100:.2f}%")
    print(f"   ‚Ä¢ % de TPM l√≠mite: {(tokens_current/tpm_limit)*100:.2f}%")
    print()
    
    if requests_current < rpm_target * 0.5:
        print("   ‚ö†Ô∏è  Est√°s usando menos del 50% de tu capacidad RPM")
        print("   üí° Puedes aumentar el batch_size significativamente")
    elif requests_current < rpm_target:
        print("   ‚úÖ Est√°s dentro del rango √≥ptimo")
    else:
        print("   ‚ö†Ô∏è  Est√°s cerca del l√≠mite, considera reducir")
    
    print()
    print("=" * 80)
    print("üöÄ RECOMENDACIONES")
    print("=" * 80)
    print()
    print(f"‚úÖ Batch size recomendado: {batch_size_optimal}")
    print(f"‚úÖ Puedes procesar en paralelo: hasta 10 workers")
    print(f"‚úÖ Con {batch_size_optimal} archivos/batch:")
    print(f"   ‚Ä¢ Requests: ~{batch_size_optimal * avg_chunks_per_file:,} por batch")
    print(f"   ‚Ä¢ Tokens: ~{batch_size_optimal * avg_tokens_per_file:,} por batch")
    print(f"   ‚Ä¢ Velocidad: ~{batch_size_optimal * 60 / 2:.0f} archivos/hora (estimado)")
    print()
    print("üí° VENTAJAS DE TIER 3:")
    print("   ‚Ä¢ L√≠mites muy altos (5M TPM, 5K RPM)")
    print("   ‚Ä¢ Puedes procesar cientos de libros sin problemas")
    print("   ‚Ä¢ Procesamiento paralelo seguro")
    print("   ‚Ä¢ No necesitas preocuparte por l√≠mites diarios")
    print()
    
except Exception as e:
    print(f"‚ùå Error: {e}")
    import traceback
    traceback.print_exc()

print("=" * 80)



