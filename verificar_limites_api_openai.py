"""
üîç VERIFICAR L√çMITES DE OPENAI DESDE API
=========================================

Intenta obtener l√≠mites usando diferentes endpoints de OpenAI
"""

import os
import sys
import requests
import json
from dotenv import load_dotenv

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

load_dotenv()

def get_env(key):
    value = os.getenv(key, "")
    if not value:
        for env_key in os.environ.keys():
            if env_key.strip().lstrip('\ufeff') == key:
                value = os.environ[env_key]
                break
    return value.strip('"').strip("'").strip()

OPENAI_API_KEY = get_env("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    print("‚ùå Error: OPENAI_API_KEY no est√° configurada")
    sys.exit(1)

headers = {
    "Authorization": f"Bearer {OPENAI_API_KEY}",
    "Content-Type": "application/json"
}

print("=" * 80)
print("üîç VERIFICACI√ìN DE L√çMITES DE OPENAI DESDE API")
print("=" * 80)
print()

# 1. Intentar endpoint de fine-tuning model limits
print("1Ô∏è‚É£  INTENTANDO: /v1/fine_tuning/model_limits")
print("-" * 80)
try:
    response = requests.get(
        "https://api.openai.com/v1/fine_tuning/model_limits",
        headers=headers,
        timeout=10
    )
    
    if response.status_code == 200:
        data = response.json()
        print("   ‚úÖ Respuesta exitosa:")
        print(f"   {json.dumps(data, indent=2)}")
        print()
        print("   ‚ö†Ô∏è  NOTA: Este endpoint es para l√≠mites de fine-tuning,")
        print("      no para rate limits (RPM/TPM) de embeddings")
    else:
        print(f"   ‚ö†Ô∏è  Error {response.status_code}: {response.text[:200]}")
except Exception as e:
    print(f"   ‚ùå Error: {e}")

print()

# 2. Intentar hacer una llamada real a embeddings y ver headers
print("2Ô∏è‚É£  INTENTANDO: Llamada real a embeddings (ver headers)")
print("-" * 80)
try:
    response = requests.post(
        "https://api.openai.com/v1/embeddings",
        headers=headers,
        json={
            "model": "text-embedding-3-small",
            "input": "test"
        },
        timeout=10
    )
    
    print(f"   Status code: {response.status_code}")
    
    # Buscar headers de rate limit
    rate_limit_headers = {}
    for key, value in response.headers.items():
        if 'ratelimit' in key.lower():
            rate_limit_headers[key] = value
    
    if rate_limit_headers:
        print("   ‚úÖ Headers de rate limit encontrados:")
        for key, value in sorted(rate_limit_headers.items()):
            print(f"      ‚Ä¢ {key}: {value}")
    else:
        print("   ‚ö†Ô∏è  No se encontraron headers de rate limit")
    
    if response.status_code == 200:
        print("   ‚úÖ Llamada exitosa")
    else:
        print(f"   ‚ö†Ô∏è  Error: {response.text[:200]}")
        
except Exception as e:
    print(f"   ‚ùå Error: {e}")

print()

# 3. Intentar endpoint de modelos
print("3Ô∏è‚É£  INTENTANDO: /v1/models (listar modelos)")
print("-" * 80)
try:
    response = requests.get(
        "https://api.openai.com/v1/models",
        headers=headers,
        timeout=10
    )
    
    if response.status_code == 200:
        data = response.json()
        models = data.get('data', [])
        embedding_models = [m for m in models if 'embedding' in m.get('id', '').lower()]
        
        print(f"   ‚úÖ Encontrados {len(embedding_models)} modelos de embedding:")
        for model in embedding_models[:5]:  # Mostrar primeros 5
            print(f"      ‚Ä¢ {model.get('id')}")
        
        if len(embedding_models) > 5:
            print(f"      ... y {len(embedding_models) - 5} m√°s")
    else:
        print(f"   ‚ö†Ô∏è  Error {response.status_code}: {response.text[:200]}")
except Exception as e:
    print(f"   ‚ùå Error: {e}")

print()

# 4. Intentar endpoint de organizaci√≥n
print("4Ô∏è‚É£  INTENTANDO: /v1/organizations")
print("-" * 80)
try:
    response = requests.get(
        "https://api.openai.com/v1/organizations",
        headers=headers,
        timeout=10
    )
    
    if response.status_code == 200:
        data = response.json()
        print("   ‚úÖ Organizaciones encontradas:")
        if data.get('data'):
            for org in data['data']:
                print(f"      ‚Ä¢ {org.get('name', 'Sin nombre')} (ID: {org.get('id', 'N/A')})")
        else:
            print("      ‚ö†Ô∏è  No se encontraron organizaciones")
    else:
        print(f"   ‚ö†Ô∏è  Error {response.status_code}")
        if response.status_code == 401:
            print("      (Requiere permisos de organizaci√≥n)")
        else:
            print(f"      {response.text[:200]}")
except Exception as e:
    print(f"   ‚ùå Error: {e}")

print()

# 5. Resumen y recomendaciones
print("=" * 80)
print("üìã RESUMEN Y RECOMENDACIONES")
print("=" * 80)
print()

print("‚úÖ M√âTODO M√ÅS CONFIABLE:")
print("   Los headers de rate limit en las respuestas de la API son la forma")
print("   m√°s precisa de conocer tus l√≠mites reales:")
print()
print("   ‚Ä¢ x-ratelimit-limit-requests: Tu l√≠mite de RPM")
print("   ‚Ä¢ x-ratelimit-limit-tokens: Tu l√≠mite de TPM")
print()

print("üìä SOBRE TIER 2:")
print("   ‚Ä¢ Tier 2 significa: $50 pagados + 7+ d√≠as desde primer pago")
print("   ‚Ä¢ L√≠mite de uso: $500/mes")
print("   ‚Ä¢ Los rate limits (RPM/TPM) var√≠an por modelo y organizaci√≥n")
print("   ‚Ä¢ Tier 2 generalmente tiene l√≠mites m√°s altos que Tier 1")
print()

print("üí° PARA VERIFICAR TUS L√çMITES EXACTOS:")
print("   1. Ve a: https://platform.openai.com/settings/organization/limits")
print("   2. Busca 'text-embedding-3-small'")
print("   3. Verifica RPM y TPM mostrados")
print("   4. O usa los headers de las respuestas de la API (m√©todo m√°s preciso)")
print()

print("üîß EL ENDPOINT DE FINE-TUNING:")
print("   ‚Ä¢ /v1/fine_tuning/model_limits muestra l√≠mites de fine-tuning")
print("   ‚Ä¢ NO muestra rate limits (RPM/TPM) para embeddings")
print("   ‚Ä¢ √ötil solo si planeas hacer fine-tuning")
print()




