# üîÑ GU√çA DE REUTILIZACI√ìN DE LA INFRAESTRUCTURA RAG

## üìã Visi√≥n General

Esta infraestructura RAG est√° dise√±ada para ser **completamente reutilizable** en diferentes proyectos. Puedes usarla para:

- Indexar documentos en cualquier proyecto
- Crear sistemas RAG personalizados
- Integrar b√∫squeda sem√°ntica en aplicaciones
- Procesar y analizar grandes vol√∫menes de documentos

---

## üèóÔ∏è Estructura Modular

La infraestructura est√° organizada en m√≥dulos independientes:

```
rag_infrastructure/
‚îú‚îÄ‚îÄ __init__.py              # Exportaciones principales
‚îú‚îÄ‚îÄ pipeline.py              # Pipeline principal
‚îú‚îÄ‚îÄ config.py                # Configuraci√≥n
‚îú‚îÄ‚îÄ ingestion.py             # Motor de ingesta
‚îú‚îÄ‚îÄ monitor.py               # Monitor y reportes
‚îú‚îÄ‚îÄ anti_duplicates.py       # Sistema anti-duplicados
‚îú‚îÄ‚îÄ metadata_extractor.py    # Extracci√≥n de metadatos
‚îú‚îÄ‚îÄ error_logger.py          # Logging de errores
‚îî‚îÄ‚îÄ rag_search.py            # B√∫squeda con filtros
```

Cada m√≥dulo puede usarse **independientemente** o como parte del pipeline completo.

---

## üöÄ Uso B√°sico: Pipeline Completo

### Instalaci√≥n

1. Copia la carpeta `rag_infrastructure/` a tu proyecto
2. Instala dependencias:
   ```bash
   pip install llama-index openai psycopg2-binary python-dotenv
   ```

### Ejemplo M√≠nimo

```python
from rag_infrastructure import RAGIngestionPipeline

# Crear pipeline
pipeline = RAGIngestionPipeline(
    data_directory="./documents",
    supabase_url="https://xxx.supabase.co",
    supabase_password="tu_password",
    openai_api_key="sk-..."
)

# Ejecutar ingesta
results = pipeline.ingest()

# Realizar b√∫squeda
resultados = pipeline.search(
    query="¬øQu√© es machine learning?",
    language="es",
    category="tecnolog√≠a"
)
```

---

## üîß Uso Avanzado: M√≥dulos Individuales

### 1. Solo Extracci√≥n de Metadatos

```python
from rag_infrastructure.metadata_extractor import extract_rich_metadata

metadata = extract_rich_metadata(
    file_path="./documento.pdf",
    text="Texto extra√≠do del documento..."
)

print(f"T√≠tulo: {metadata['title']}")
print(f"Autor: {metadata['author']}")
print(f"Idioma: {metadata['language']}")
print(f"Categor√≠a: {metadata['category']}")
```

### 2. Solo Sistema Anti-Duplicados

```python
from rag_infrastructure.anti_duplicates import (
    calculate_doc_id,
    check_document_exists,
    register_document
)

# Calcular ID √∫nico
doc_id = calculate_doc_id("./documento.pdf")

# Verificar si existe
exists, doc_info = check_document_exists(doc_id)

if not exists:
    # Registrar nuevo documento
    register_document(
        doc_id=doc_id,
        filename="documento.pdf",
        file_path="./documento.pdf",
        title="Mi Documento",
        author="Autor",
        language="es",
        category="general"
    )
```

### 3. Solo B√∫squeda con Filtros

```python
from rag_infrastructure.rag_search import search_with_filters

resultados = search_with_filters(
    query="estrategias de inversi√≥n",
    top_k=10,
    language="es",
    category="finanzas",
    year_min=2020
)

for resultado in resultados:
    print(f"T√≠tulo: {resultado['document_info']['title']}")
    print(f"Contenido: {resultado['content'][:200]}...")
```

### 4. Solo Logging de Errores

```python
from rag_infrastructure.error_logger import log_error, ErrorType

try:
    # Tu c√≥digo aqu√≠
    process_document()
except Exception as e:
    log_error(
        filename="documento.pdf",
        error_type=ErrorType.EXTRACTION_ERROR,
        error_message=str(e),
        exception=e
    )
```

---

## üéØ Casos de Uso Comunes

### Caso 1: Sistema de Documentaci√≥n T√©cnica

```python
pipeline = RAGIngestionPipeline(
    data_directory="./docs",
    supabase_url="...",
    supabase_password="...",
    openai_api_key="...",
    collection_name="technical_docs"
)

# Indexar documentaci√≥n
pipeline.ingest()

# Buscar en documentaci√≥n
resultados = pipeline.search(
    query="c√≥mo usar la API",
    category="documentaci√≥n"
)
```

### Caso 2: Biblioteca de Libros

```python
pipeline = RAGIngestionPipeline(
    data_directory="./libros",
    supabase_url="...",
    supabase_password="...",
    openai_api_key="...",
    collection_name="library"
)

# Indexar libros
pipeline.ingest()

# Buscar por autor y a√±o
resultados = pipeline.search(
    query="psicolog√≠a positiva",
    author="Seligman",
    year_min=2010
)
```

### Caso 3: Base de Conocimiento Empresarial

```python
pipeline = RAGIngestionPipeline(
    data_directory="./knowledge_base",
    supabase_url="...",
    supabase_password="...",
    openai_api_key="...",
    collection_name="company_kb"
)

# Indexar documentos internos
pipeline.ingest()

# Buscar por departamento (categor√≠a)
resultados = pipeline.search(
    query="pol√≠ticas de recursos humanos",
    category="RRHH"
)
```

---

## üîå Integraci√≥n con Otros Frameworks

### Con FastAPI

```python
from fastapi import FastAPI
from rag_infrastructure import RAGIngestionPipeline

app = FastAPI()
pipeline = RAGIngestionPipeline(...)

@app.post("/ingest")
async def ingest_documents():
    results = pipeline.ingest()
    return results

@app.get("/search")
async def search(query: str, language: str = None):
    resultados = pipeline.search(query=query, language=language)
    return resultados
```

### Con Flask

```python
from flask import Flask, request, jsonify
from rag_infrastructure import RAGIngestionPipeline

app = Flask(__name__)
pipeline = RAGIngestionPipeline(...)

@app.route('/search', methods=['POST'])
def search():
    data = request.json
    resultados = pipeline.search(
        query=data['query'],
        language=data.get('language'),
        category=data.get('category')
    )
    return jsonify(resultados)
```

### Con Django

```python
# views.py
from django.http import JsonResponse
from rag_infrastructure import RAGIngestionPipeline

pipeline = RAGIngestionPipeline(...)

def search_view(request):
    query = request.GET.get('query')
    resultados = pipeline.search(query=query)
    return JsonResponse({'results': resultados})
```

---

## ‚öôÔ∏è Configuraci√≥n Personalizada

### Variables de Entorno

Crea un archivo `.env`:

```env
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_DB_PASSWORD=tu_password
OPENAI_API_KEY=sk-...
DATA_DIRECTORY=./documents
COLLECTION_NAME=knowledge
CHUNK_SIZE=1024
CHUNK_OVERLAP=200
EMBEDDING_BATCH_SIZE=30
MAX_WORKERS=15
```

### Configuraci√≥n Program√°tica

```python
from rag_infrastructure import RAGIngestionPipeline

pipeline = RAGIngestionPipeline(
    data_directory="./custom_docs",
    supabase_url="...",
    supabase_password="...",
    openai_api_key="...",
    # Personalizar
    chunk_size=2048,           # Chunks m√°s grandes
    chunk_overlap=400,          # M√°s overlap
    embedding_batch_size=50,    # Batches m√°s grandes
    max_workers=20,             # M√°s workers
    embedding_model="text-embedding-3-large"  # Modelo diferente
)
```

---

## üì¶ Empaquetado para Distribuci√≥n

### Crear Paquete Instalable

Crea `setup.py`:

```python
from setuptools import setup, find_packages

setup(
    name="rag-infrastructure",
    version="1.0.0",
    packages=find_packages(),
    install_requires=[
        "llama-index",
        "openai",
        "psycopg2-binary",
        "python-dotenv",
    ],
    extras_require={
        "metadata": ["PyPDF2", "langdetect"],
    }
)
```

Instalar:
```bash
pip install -e .
```

---

## üîÑ Migraci√≥n de Proyectos Existentes

### Paso 1: Copiar Infraestructura

```bash
cp -r rag_infrastructure/ /ruta/nuevo/proyecto/
```

### Paso 2: Adaptar Configuraci√≥n

```python
# En tu nuevo proyecto
from rag_infrastructure import RAGIngestionPipeline

# Usar tu configuraci√≥n existente
pipeline = RAGIngestionPipeline(
    data_directory=TU_DATA_DIR,
    supabase_url=TU_SUPABASE_URL,
    supabase_password=TU_PASSWORD,
    openai_api_key=TU_API_KEY
)
```

### Paso 3: Migrar Datos (si es necesario)

Si ya tienes datos indexados, la infraestructura los detectar√° autom√°ticamente gracias al sistema anti-duplicados.

---

## üé® Personalizaci√≥n Avanzada

### Extender Extracci√≥n de Metadatos

```python
from rag_infrastructure.metadata_extractor import extract_rich_metadata

def custom_metadata_extractor(file_path, text):
    # Tu l√≥gica personalizada
    metadata = extract_rich_metadata(file_path, text)
    
    # Agregar campos personalizados
    metadata['custom_field'] = "valor"
    
    return metadata
```

### Agregar Nuevas Categor√≠as

```python
from rag_infrastructure.metadata_extractor import classify_category

# Modificar la funci√≥n classify_category para agregar nuevas categor√≠as
# O crear tu propia funci√≥n de clasificaci√≥n
```

### Personalizar B√∫squeda

```python
from rag_infrastructure.rag_search import search_with_filters

def custom_search(query, **filters):
    # Tu l√≥gica personalizada antes de buscar
    preprocessed_query = preprocess(query)
    
    # Usar b√∫squeda est√°ndar
    resultados = search_with_filters(preprocessed_query, **filters)
    
    # Post-procesar resultados
    return postprocess(resultados)
```

---

## üìä Monitoreo y Reportes

El pipeline incluye monitor y reportes autom√°ticos:

```python
pipeline = RAGIngestionPipeline(...)
results = pipeline.ingest()

# El reporte se genera autom√°ticamente
# Se guarda en: ingestion_report_YYYYMMDD_HHMMSS.md

# Tambi√©n puedes acceder a estad√≠sticas
stats = pipeline.monitor.get_stats()
print(f"Archivos procesados: {stats.files_processed}")
print(f"Chunks generados: {stats.total_chunks}")
```

---

## üêõ Debugging y Troubleshooting

### Ver Logs de Errores

```python
from rag_infrastructure.error_logger import get_error_summary, get_recent_errors

# Resumen de errores
summary = get_error_summary()
print(f"Total errores: {summary['total_errors']}")

# Errores recientes
recent = get_recent_errors(limit=10)
for error in recent:
    print(f"{error['filename']}: {error['error_type']}")
```

### Verificar Estado de Tablas

```python
from rag_infrastructure.anti_duplicates import ensure_documents_table
from rag_infrastructure.error_logger import ensure_errors_table

# Verificar/crear tablas
ensure_documents_table()
ensure_errors_table()
```

---

## ‚úÖ Checklist de Reutilizaci√≥n

- [ ] Copiar carpeta `rag_infrastructure/` al nuevo proyecto
- [ ] Instalar dependencias (`pip install ...`)
- [ ] Configurar variables de entorno (`.env`)
- [ ] Crear instancia de `RAGIngestionPipeline`
- [ ] Ejecutar `pipeline.ingest()`
- [ ] Probar b√∫squedas con `pipeline.search()`
- [ ] Personalizar seg√∫n necesidades
- [ ] Integrar con tu aplicaci√≥n (FastAPI, Flask, etc.)

---

## üéâ ¬°Listo!

Tu infraestructura RAG est√° lista para ser reutilizada en cualquier proyecto. Es modular, extensible y completamente funcional.

**¬øNecesitas ayuda?** Revisa los ejemplos en `EJEMPLO_BUSQUEDA_FILTROS.py` y `EJEMPLO_ERROR_LOGGING.md`.

